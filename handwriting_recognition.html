<!DOCTYPE HTML>
<!--
-->
<html>
	<head>
		<title>Xiao Tianyou Theo's Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Theo</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Projects</a></li>
							<li class="active"><a href="handwriting_recognition.html">Handwriting</a></li>
							<li><a href="binary_search.html">Binary_Search</a></li>
							<li><a href="investment.html">Investment</a></li>
							<li><a href="passion_computing.html">Passion_Programming</a></li>
							<li><a href="myself.html">Myself</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://github.com/theo-xiao-sg" class="icon brands fa-github" target="_blank"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<h1>Mouse-writing recognition
									using KNN and Neural Network</h1>
									<a href="https://github.com/theo-xiao-sg/handwriting_recognition" target="_blank" class="button">Source code</a>
									<p> </p>
									<p>Demonstration in a GIF format:</p>
									<img src = "images/handwriting_recog_demo.gif">
								</header>
								<!-- Lists -->
									<h3>Introduction</h3>
									<p>
									Driven by a strong interest in handwriting recognition, I undertook the task of developing a number recognition system to convert
									handwritten numbers into accurate digital representations. This involved the meticulous process of coding and algorithmic exploration
									to ensure the reliability and precision of the system. </p>
									<h3>Data</h3>
									<p>To maximize interactivity, my goal was to develop an interactive tool using Pygame, allowing users to actively engage with it using a mouse.
										In the initial stages, I chose to leverage my experience with the MNIST dataset (<a href="https://www.nist.gov/itl/products-and-services/emnist-dataset">link</a>).
										Although the MNIST dataset is commonly used for handwriting recognition,
										it primarily consisted of handwritten digits rather than characters written with a mouse. As a result, the model trained using the MNIST dataset encountered
										challenges in accurately recognizing mouse-written characters. </p>
									<p>To address this limitation, I decided to replace the MNIST dataset with 1447 real mouse-written images
										to train the models for recognizing characters specifically written with a mouse. This substitution enhanced the dataset's representativeness for my
										experiment, as it now contained more relevant and diverse samples of mouse-written characters.</p>
									<h3>Models</h3>
									<p>I utilized two primary methods, namely K-Nearest Neighbors (KNN) and Neural Network, to analyze and compare their performance in recognizing
										mouse-written characters. To ensure a fair evaluation, I divided the dataset into a training set (70%) and a testing set (30%). Then, I measured
										the accuracy of both models using the testing set. The results are as follows:</p>
									<p>K-Nearest Neighbors (KNN) achieved the accuracy of 80-89% on the testing set using different numbers of neighbours. </p>
								<style>
									pre {
										tab-size: 4;
									}
								</style>
								<pre><code>model training for num_neighbors: 1 ...
num_neighbors: 1, accuracy: 88.97%

model training for num_neighbors: 3 ...
num_neighbors: 3, accuracy: 84.14%

model training for num_neighbors: 5 ...
num_neighbors: 5, accuracy: 83.45%

model training for num_neighbors: 7 ...
num_neighbors: 7, accuracy: 82.07%

model training for num_neighbors: 9 ...
num_neighbors: 9, accuracy: 80.92%
</code></pre>

									<p>The Neural Network model attained the accuracy of 82-86% on the same testing set using one hidden layer and different number of neurons. I also tested multiple hidden layers but with very little improvement.</p>
									<style>
									pre {
										tab-size: 4;
									}
								</style>
								<pre><code>model training for number_of_neurons_i: 100 ...
number_of_neurons_i: 100, accuracy: 82.99%

model training for number_of_neurons_i: 300 ...
number_of_neurons_i: 300, accuracy: 83.68%

model training for number_of_neurons_i: 500 ...
number_of_neurons_i: 500, accuracy: 83.45%

model training for number_of_neurons_i: 700 ...
number_of_neurons_i: 700, accuracy: 84.60%

model training for number_of_neurons_i: 900 ...
number_of_neurons_i: 900, accuracy: 85.52%

model training for number_of_neurons_i: 1100 ...
number_of_neurons_i: 1100, accuracy: 86.21%
</code></pre>
<h3>Real life test and Discussion</h3>
<p>After comparing the results, it became evident that both models achieved similar levels of accuracy on the testing dataset. However, to assess their performance
	in real-life scenarios, I decided to go a step further. I deployed the models using a pygame GUI and actively interacted with them, particularly testing them on
	my messy and challenging mouse-written samples.</p>
<p>Based on my practical experience, the neural network model exhibited superior capabilities in effectively handling these difficult mouse-written samples. The model
	proved to be more adept at accurately recognizing and interpreting the messy handwriting. To illustrate the model and Pygame GUI, I have prepared animations and videos that demonstrate
	how the tool handles both normal and messy mouse writings, providing visual illustrations of its functionality.</p>
<p>To gain a better understanding of the models' performance, I have shared the codes and models (pkl files) on my GitHub repository (<a href="https://github.com/theo-xiao-sg/handwriting_recognition">source codes</a>). I invite you to explore and experiment with them.
	You can find the readme file on how to deploy and use this tool here (<a href="https://github.com/theo-xiao-sg/handwriting_recognition#readme">readme</a>). </p>


							    <header class="major">
									<p>Demonstration in a GIF format:</p>
									<img src = "images/handwriting_recog_demo.gif">
								</header>
							<p>
								<br/>
								</p>
								<header class="major">
									<p>Demonstration in a MP4 format:</p>
									<video width="640" height="512" autoplay muted controls loop>
										<source src="images/handwriting_recog_demo.mp4" type="video/mp4">									  
									  Your browser does not support the video tag.									  
									  </video>
								</header>
							</section>

					</div>
		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>